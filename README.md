# PUCRJ-ED-MVP
Projeto MVP para compor nota da PÃ³s GraduaÃ§Ã£o de CiÃªncia de Dados e Analytics, Sprint de Engenharia de Dados, na PUC-RJ
Link para acesso ao cÃ³digo publicado no Databricks Community: https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/2263258057188516/2676582161827454/799048061560195/latest.html

# ğŸ“Š Pipeline de Dados PortuÃ¡rios com Spark em Databricks

Este projeto Ã© parte do MVP da Sprint de Engenharia de Dados do curso de PÃ³s-GraduaÃ§Ã£o em CiÃªncia de Dados e Analytics. O objetivo Ã© criar um pipeline de ingestÃ£o, tratamento e anÃ¡lise de dados estatÃ­sticos aquaviÃ¡rios do Brasil, utilizando tecnologias na nuvem com foco no Databricks e Apache Spark.

## ğŸš¢ Contexto

O setor portuÃ¡rio brasileiro Ã© essencial para a movimentaÃ§Ã£o de cargas. Uma anÃ¡lise adequada desses dados pode:
- Melhorar a gestÃ£o de portos,
- Reduzir custos operacionais,
- Otimizar processos de atracaÃ§Ã£o, carregamento e transporte.

## ğŸ¯ Objetivo

Responder, de forma rÃ¡pida e clara, a perguntas estratÃ©gicas usando dados histÃ³ricos disponibilizados pela ANTAQ:

1. Qual Ã© o tempo mÃ©dio de atracaÃ§Ã£o por porto?
2. Qual o volume total de carga movimentada por ano?
3. Qual Ã© o total movimentado por tipo de carga?
4. Quais sÃ£o os terminais portuÃ¡rios mais utilizados?
5. Quais sÃ£o os portos com maior nÃºmero de atracaÃ§Ãµes?
6. Quais tipos de mercadoria sÃ£o mais movimentados por navegaÃ§Ã£o de longo curso?
7. Qual o tempo mÃ©dio de viagem por tipo de navio?

## ğŸ“ Fonte de Dados

**EstatÃ­stico AquaviÃ¡rio - ANTAQ**  
ğŸ”— [Acesse aqui](https://web3.antaq.gov.br/ea/sense/download.html#pt)  
PerÃ­odo coberto: **2020 a 2024**

### Tabelas utilizadas:
- AtracaÃ§Ã£o
- Carga
- Carga Conteinerizada
- Tempos de AtracaÃ§Ã£o
- Taxa de OcupaÃ§Ã£o
- Carga por RegiÃ£o HidrogrÃ¡fica, Hidrovia e Rio

## ğŸ› ï¸ Tecnologias

- **Apache Spark (PySpark)**
- **SQL**
- **Databricks**
- **Python**
- **DBFS (Databricks File System)**
- **Pandas (para manipulaÃ§Ã£o auxiliar de dados)**

## ğŸ”„ Pipeline

1. **Leitura dos arquivos CSV armazenados no DBFS**
2. **Tratamento de arquivos particionados (.txt_part)**
3. **UniÃ£o dos dados de diferentes partes**
4. **PadronizaÃ§Ã£o dos nomes das colunas**
5. **VisualizaÃ§Ã£o dos dados via SQL**

## ğŸ§ª ExecuÃ§Ã£o no Databricks

- O cÃ³digo deve ser executado em um notebook no ambiente Databricks.
- Os arquivos .txt devem estar previamente carregados na pasta `/FileStore/tables/` do DBFS.
- Algumas operaÃ§Ãµes requerem permissÃµes de escrita/leitura no cluster em uso.
- A leitura dos arquivos assume o uso de delimitador `;` e presenÃ§a de cabeÃ§alho.

## ğŸŒ Acesso ao Projeto

VocÃª pode acessar o notebook completo neste link:  
ğŸ”— [Databricks Notebook](https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/2263258057188516/2676582161827454/799048061560195/latest.html)

## ğŸ“Œ ObservaÃ§Ãµes

- Os dados particionados sÃ£o reunidos automaticamente com base em padrÃµes de nomenclatura dos arquivos.
- Nomes de colunas sÃ£o limpos para evitar problemas com caracteres especiais.

## ğŸ‘©ğŸ»â€ğŸ’» Autora

**Marina Rezende**  
Projeto desenvolvido como parte da formaÃ§Ã£o em Engenharia de Dados.
"""

